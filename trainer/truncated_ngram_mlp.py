import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from keras.callbacks import TensorBoard
from trainer.mlp import MLP
from keras.optimizers import *
from keras.preprocessing.sequence import pad_sequences

from data import read_data_file, read_label_file


def truncNgramMLP():
    data_file = "./Data/train/real_train_data.csv"
    label_file = "./Data/train/real_train_label.csv"

    # data_file = "./Data/train/train.csv"
    # label_file = "./Data/train/train_label.csv"

    X = read_data_file(data_file)
    X = pad_sequences(X, maxlen=328, dtype='int32', padding='post', truncating='post')
    y = read_label_file(label_file)

    # print ("Shape of train data(m):\n", X.shape)
    # print ("Data:\n", X[0:5], "\n")
    # print ("Shape of train label:", y.shape)
    # print ("Label:\n", y[0:5], "\n")

    str_X = []
    for i in range(X.shape[0]):
        str_X.append(','.join([str(k) for k in X[i]]))

    df = pd.DataFrame(str_X, index=range(X.shape[0]), columns=['data'])
    # Apply ngram and Tfidf to
    tfidf = TfidfVectorizer(analyzer="word", max_features=5000, ngram_range=(2, 4))

    # print(tfidf)
    X_transformed = tfidf.fit_transform(df.data)
    # test_transformed = tfidf.fit_transform()

    X_train, X_test, y_train, y_test = train_test_split(X_transformed,
                                                        y,
                                                        test_size=0.2,
                                                        random_state=42)

    # Success
    print("Training and testing split was successful.")
    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)

    mlp_model = MLP(X_train.shape[1])

    print(mlp_model.summary())

    tensorBoardCallback = TensorBoard(log_dir='./logs/trunc_ngram_mlp', write_graph=X.shape[1])

    optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-4, amsgrad=False)
    # optimizer = SGD(lr=0.01, momentum=0.9, decay=1e-6, nesterov=False)

    mlp_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])

    mlp_model.fit(X_train, y_train, callbacks=[tensorBoardCallback], epochs=20, batch_size=128)

    score, acc = mlp_model.evaluate(X_test, y_test, verbose=2, batch_size=128)
    print("score: %.2f" % (score))
    print("acc: %.2f" % (acc))
