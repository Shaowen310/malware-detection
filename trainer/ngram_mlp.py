from keras.models import Sequential
from keras.optimizers import RMSprop
from keras.callbacks import EarlyStopping, TensorBoard
from keras.layers import Dense, Dropout, Embedding, Conv1D, Multiply, Flatten
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.model_selection import train_test_split
import pandas as pd


def ngramMLP():
    train = pd.read_csv("./Data/train/train.csv", header=None, sep="|", names=['row_data'], error_bad_lines=False)
    label = pd.read_csv("./Data/train/train_label.csv", sep=",", error_bad_lines=False)
    test = pd.read_csv("./Data/test/test.csv", header=None, sep="|", names=['row_data'], error_bad_lines=False)

    train_sub = train.sample(frac=0.1, replace=True, random_state=5242)
    label_sub = label.sample(frac=0.1, replace=True, random_state=5242)
    label_sub.drop('sample_id', axis=1, inplace=True)
    print('Shape of the sub train data: ', train_sub.shape)
    print('Shape of the sub label data: ', label_sub.shape)
    print('Shape of the test data: ', test.shape)

    print(train_sub.head())

    tfidf = TfidfVectorizer(analyzer="word", max_features=5000, ngram_range=(2, 4))
    features = tfidf.fit_transform(train_sub.row_data.append(test.row_data))

    train_tf_idf = features[:train_sub.row_data.shape[0]]
    test_tf_idf = features[train_sub.row_data.shape[0]:]

    x_train, x_val, y_train, y_val = train_test_split(train_tf_idf, label_sub, test_size=0.05, random_state=5242)

    print('Shape of the sub train data: ', x_train.shape)
    print('Shape of the sub train data: ', y_train.shape)


    tensorBoardCallback = TensorBoard(log_dir='./logs/ngram_rnn', write_graph=True)


    model = Sequential()
    model.add(Dense(256, activation='relu', input_shape=(x_train.shape[1],)))
    model.add(Dense(64, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(16, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(1, activation='sigmoid'))

    model.summary()

    early_stopping = EarlyStopping(monitor='val_loss', patience=3)

    model.compile(loss='binary_crossentropy',
                  optimizer=RMSprop(),
                  metrics=['accuracy'])

    history = model.fit(x_train, y_train,
                        batch_size=32,
                        epochs=32,
                        verbose=1,
                        callbacks=[early_stopping, tensorBoardCallback],
                        validation_data=(x_val, y_val))

    score,acc = model.evaluate(x_val, y_val, verbose = 2, batch_size = 64)
    print("score: %.2f" % (score))
    print("acc: %.2f" % (acc))


    predictions = model.predict_classes(test_tf_idf)
    print(predictions)

    pd.DataFrame(predictions).to_csv("./Data/prediction" + '.csv', index=True)

