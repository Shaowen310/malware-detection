## import
import numpy as np
import pandas as pd
from data_header_extrac import extract_header, read_label_file
from sklearn.model_selection import train_test_split
from keras.models import Model
from keras.layers import Input, Embedding, Conv1D, Dropout, Flatten, Concatenate, Dense, Convolution1D, Add, GlobalMaxPooling1D, GlobalAveragePooling1D
from keras.callbacks import EarlyStopping
from sklearn.metrics import roc_auc_score

## arguments
data_file = "./../Data/train/train.csv"
label_file = "./../Data/train/train_label.csv"
model_1_save = "./model1.h5"
model_2_save = "./model2.h5"
model_3_save = "./model3.h5"

## data preprocess
print('\ndata processing started ...')

X, skip_idx = extract_header(data_file, False)
y = read_label_file(label_file)
y = np.delete(y, skip_idx, 0)

print ("Shape of train data(m):\n", X.shape)
print ("Shape of train label:", y.shape)

X_max_timesteps = X.shape[1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5242)

print ("Training and testing split was successful.")
print (X_train.shape, y_train.shape, X_test.shape, y_test.shape)

## models
## CNN Ensemble (model 1)
def cnn_ensemble(length, vocab_size):
    inputs = Input(shape=(length,))
    
    # embedding
    embedding = Embedding(vocab_size, 8)(inputs)
    
    # conv channel 1
    conv1 = Conv1D(filters=32, kernel_size=400, strides=400, padding='same',activation='relu')(embedding)
    conv1 = Dropout(0.5)(conv1)
    conv1 = Flatten()(conv1)
    
    # conv channel 2
    conv2 = Conv1D(filters=32, kernel_size=500, strides=500, padding='same',activation='relu')(embedding)
    conv2 = Dropout(0.5)(conv2)
    conv2 = Flatten()(conv2)
    
    # conv channel 3
    conv3 = Conv1D(filters=32, kernel_size=600, strides=600, padding='same',activation='relu')(embedding)
    conv3 = Dropout(0.5)(conv3)
    conv3 = Flatten()(conv3)
    
    # merge
    merged = Concatenate()([conv1, conv2, conv3])
    
    # interpretation
    dense1 = Dense(128, activation='relu')(merged)
    dense1 = Dropout(0.2)(dense1)

    outputs = Dense(1, activation='sigmoid')(dense1)
    
    model = Model(inputs=inputs, outputs=outputs)
    
    # compile
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    
    return model

print('\ntraining CNN ensemble ...')
cnn_ensemble_model = cnn_ensemble(X_max_timesteps, 257)

print(cnn_ensemble_model.summary())

early_stopping = EarlyStopping(monitor='val_loss', patience=5)

cnn_ensemble_model.fit(X_train, y_train, callbacks=[early_stopping], 
          epochs=40, batch_size=256, validation_data=(X_test, y_test))

score, acc = cnn_ensemble_model.evaluate(X_test, y_test, verbose=0)
print("score: %.8f" % (score))
print("acc: %.8f" % (acc))

cnn_ensemble_pred = cnn_ensemble_model.predict(X_test)
score =roc_auc_score(y_test, cnn_ensemble_pred)
print("Total roc auc score = {0:0.8f}".format(score))

cnn_ensemble_model.save(model_1_save)

## MalConv (model 2)
def malnet(maxlen, vocab_size):
    inputs = Input(shape=(maxlen,))
    
    emb1 = Embedding(vocab_size, 8, input_length=maxlen, mask_zero=False)(inputs)

    conv1 = Convolution1D(128, 64, strides=64, padding='same', activation='relu')(emb1)

    conv2 = Convolution1D(128, 64, strides=64, padding='same', activation=None)(emb1)

    x = Add()([conv1, conv2])

    x = GlobalMaxPooling1D()(x)
    
    x = Dense(128, activation='relu')(x)
    x = Dropout(0.2)(x)

    loss_out = Dense(1, activation='sigmoid', name='loss_out')(x)

    model = Model(outputs=[loss_out], inputs=[inputs])

    return model

print('\ntraining MalNet ...')
malnet_model = malnet(X_max_timesteps, 257)

print(malnet_model.summary())

early_stopping = EarlyStopping(monitor='val_loss', patience=5)

malnet_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

malnet_model.fit(X_train, y_train, callbacks=[early_stopping],
          epochs=40, batch_size=256, validation_data=(X_test, y_test))

score,acc = malnet_model.evaluate(X_test, y_test, verbose = 2, batch_size = 256)
print("score: %.8f" % (score))
print("acc: %.8f" % (acc))

malnet_pred = malnet_model.predict(X_test)
score =roc_auc_score(y_test, malnet_pred)
print("Total roc auc score = {0:0.8f}".format(score))

malnet_model.save(model_2_save)

## model3
def model3(length, vocab_size):
    inputs = Input(shape=(length,))
    
    # embedding
    embedding = Embedding(vocab_size, 8)(inputs)
    
    # conv channel 1
    conv1 = Conv1D(filters=48, kernel_size=2, strides=2, padding='same',activation='relu')(embedding)
    conv1 = GlobalMaxPooling1D()(conv1)
    conv1 = Dropout(0.2)(conv1)
    
    # conv channel 2
    conv2 = Conv1D(filters=48, kernel_size=4, strides=4, padding='same',activation='relu')(embedding)
    conv2 = GlobalMaxPooling1D()(conv2)
    conv2 = Dropout(0.2)(conv2)
    
    # conv channel 3
    conv3 = Conv1D(filters=48, kernel_size=8, strides=8, padding='same',activation='relu')(embedding)
    conv3 = GlobalMaxPooling1D()(conv3)
    conv3 = Dropout(0.2)(conv3)
    
    # conv channel 4
    conv4 = Conv1D(filters=48, kernel_size=16, strides=16, padding='same', activation='relu')(embedding)
    conv4 = GlobalMaxPooling1D()(conv4)
    conv4 = Dropout(0.2)(conv4)

    # conv channel 5
    conv5 = Conv1D(filters=48, kernel_size=32, strides=32, padding='same', activation='relu')(embedding)
    conv5 = GlobalMaxPooling1D()(conv5)
    conv5 = Dropout(0.2)(conv5)
    
    embedding = GlobalAveragePooling1D()(embedding)
    embedding = Dropout(0.2)(embedding)
    
    # merge
    combineGating = Concatenate()([conv1, conv2, conv3, conv4, conv5, embedding])
    
    # interpretation
    dense1 = Dense(128, activation='relu')(combineGating)
    dense1 = Dropout(0.2)(dense1)

    outputs = Dense(1, activation='sigmoid')(dense1)
    model = Model(inputs=inputs, outputs=outputs)
    
    # compile
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    
    return model

print('\ntraining model3 ...')
model3_model = model3(X_max_timesteps, 257)

print(model3_model.summary())

early_stopping = EarlyStopping(monitor='val_loss', patience=5)

model3_model.fit(X_train, y_train, 
          callbacks=[early_stopping], 
          epochs=40, 
          batch_size=256,
          validation_data=(X_test, y_test))

score, acc = model3_model.evaluate(X_test, y_test, verbose=0)
print("score: %.8f" % (score))
print("acc: %.8f" % (acc))

model3_pred = model3_model.predict(X_test)
score =roc_auc_score(y_test, model3_pred)
print("Total roc auc score = {0:0.8f}".format(score))

model3_model.save(model_3_save)

## Aggregation
print('\nmodel aggregation ...')
predictions = np.zeros((X_test.shape[0], 3))
predictions[:, 0] = cnn_ensemble_pred.reshape(X_test.shape[0])
predictions[:, 1] = malnet_pred.reshape(X_test.shape[0])
predictions[:, 2] = model3_pred.reshape(X_test.shape[0])
predict_df = pd.DataFrame(predictions).mean(axis=1)
predict_np = predict_df.values
score =roc_auc_score(y_test, predict_np)
print("Total roc auc score = {0:0.8f}".format(score))
